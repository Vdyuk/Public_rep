{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "VGG_16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42a1fd29",
        "outputId": "7c8c8ac1-8993-48e3-d5dd-90bbdc434266"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "id": "42a1fd29",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c77aac62"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "from torchvision import transforms\n",
        "from multiprocessing.pool import ThreadPool\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "\n",
        "from matplotlib import colors, pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=DeprecationWarning)"
      ],
      "id": "c77aac62",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pWpcjGsgGOk",
        "outputId": "38e2f547-507e-4421-eadd-5eecda452441"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "-pWpcjGsgGOk",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8yyLNoZgDP6"
      },
      "source": [
        "!unzip /content/drive/MyDrive/journey-springfield.zip"
      ],
      "id": "t8yyLNoZgDP6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVDXj_Djf-8K"
      },
      "source": [
        "TEST_DIR = Path('/content/testset')\n",
        "TRAIN_DIR = Path('/content/train')\n",
        "\n",
        "train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\n",
        "test_files = sorted(list(TEST_DIR.rglob('*.jpg')))"
      ],
      "id": "nVDXj_Djf-8K",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19182a4e"
      },
      "source": [
        "TEST_DIR = Path('C:/Users/Vladimir/Documents/Py_works/Deep learning course/DL advanced course/journey-springfield/testset')\n",
        "TRAIN_DIR = Path('C:/Users/Vladimir/Documents/Py_works/Deep learning course/DL advanced course/journey-springfield/train')\n",
        "\n",
        "train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\n",
        "test_files = sorted(list(TEST_DIR.rglob('*.jpg')))"
      ],
      "id": "19182a4e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bcd0dfe"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_val_labels = [path.parent.name for path in train_val_files]\n",
        "train_files, val_files = train_test_split(train_val_files, test_size=0.25, \\\n",
        "                                          stratify=train_val_labels)"
      ],
      "id": "7bcd0dfe",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6451405",
        "outputId": "84b09f2b-5bb0-4c78-faab-c8cbfae49929"
      },
      "source": [
        "#val_files[0]\n",
        "train_files[0]"
      ],
      "id": "a6451405",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/train/simpsons_dataset/milhouse_van_houten/pic_0013.jpg')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3ad505b"
      },
      "source": [
        "# разные режимы датасета \n",
        "DATA_MODES = ['train', 'val', 'test']\n",
        "# все изображения будут масштабированы к размеру 224x224 px\n",
        "RESCALE_SIZE = 224\n",
        "# работаем на видеокарте\n",
        "DEVICE = torch.device(\"cuda\")"
      ],
      "id": "b3ad505b",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gR0s0mEhA7n"
      },
      "source": [
        "# постоянные метки\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "labels = [path.parent.name for path in train_val_files]\n",
        "lb = LabelEncoder().fit(labels)\n",
        "\n",
        "with open('label_encoder.pkl', 'wb') as le_dump_file:\n",
        "  pickle.dump(lb, le_dump_file)"
      ],
      "id": "2gR0s0mEhA7n",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acc552a8"
      },
      "source": [
        "class SimpsonsDataset2(Dataset):\n",
        "    \"\"\"\n",
        "    Датасет с картинками, который паралельно подгружает их из папок\n",
        "    производит скалирование и превращение в торчевые тензоры\n",
        "    \"\"\"\n",
        "    def __init__(self, files, mode):\n",
        "        super().__init__()\n",
        "        # список файлов для загрузки\n",
        "        self.files = sorted(files)\n",
        "        # режим работы\n",
        "        self.mode = mode\n",
        "\n",
        "        if self.mode not in DATA_MODES:\n",
        "            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n",
        "            raise NameError\n",
        "\n",
        "        self.len_ = len(self.files)\n",
        "     \n",
        "        self.label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n",
        "\n",
        "        if self.mode != 'test':\n",
        "            self.labels = [path.parent.name for path in self.files]\n",
        "\n",
        "                      \n",
        "    def __len__(self):\n",
        "        return self.len_\n",
        "      \n",
        "    def load_sample(self, file):\n",
        "        image = Image.open(file)\n",
        "        image.load()\n",
        "        return image\n",
        "  \n",
        "    def __getitem__(self, index):\n",
        "        # для преобразования изображений в тензоры PyTorch и нормализации входа\n",
        "        transform_a = transforms.Compose([\n",
        "            #transforms.RandomVerticalFlip(),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(15),\n",
        "            transforms.Resize(size=(224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
        "        ])\n",
        "        transform = transforms.Compose([\n",
        "            #transforms.Resize(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
        "        ])\n",
        "        \n",
        "        x = self.load_sample(self.files[index])\n",
        "\n",
        "\n",
        "        if self.mode =='test':\n",
        "            x = self._prepare_sample(x)\n",
        "            x = transform(x)\n",
        "            return x\n",
        "        elif self.mode == 'val':\n",
        "            x = self._prepare_sample(x)\n",
        "            x = transform(x)\n",
        "            label = self.labels[index]\n",
        "            label_id = self.label_encoder.transform([label])\n",
        "            y = label_id.item()\n",
        "            return x, y\n",
        "        else:\n",
        "            x = transform_a(x)\n",
        "            label = self.labels[index]\n",
        "            label_id = self.label_encoder.transform([label])\n",
        "            y = label_id.item()\n",
        "            return x, y\n",
        "\n",
        "    def _prepare_sample(self, image):\n",
        "        image = image.resize((224, 224))\n",
        "        return np.array(image)"
      ],
      "id": "acc552a8",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57a5ad68"
      },
      "source": [
        "val_dataset2 = SimpsonsDataset2(val_files, mode='val')\n",
        "    \n",
        "train_dataset2 = SimpsonsDataset2(train_files, mode='train')"
      ],
      "id": "57a5ad68",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fd65fef"
      },
      "source": [
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange"
      ],
      "id": "3fd65fef",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60c5e91e"
      },
      "source": [
        "### Модель"
      ],
      "id": "60c5e91e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb5ce386"
      },
      "source": [
        "model_VGG16 = models.vgg16(pretrained=True)"
      ],
      "id": "cb5ce386",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi3GoH7yhQ3G",
        "outputId": "6fe351fb-735d-4244-9529-5a312d4dea3d"
      },
      "source": [
        "model_VGG16"
      ],
      "id": "vi3GoH7yhQ3G",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d2a1635"
      },
      "source": [
        "'''# замораживаем полностью\n",
        "for param in model_extVGG.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "num_features = 4096\n",
        "\n",
        "model_VGG16.classifier[6] = nn.Linear(num_features, 42)\n",
        "\n",
        "model_VGG16 = model_VGG16.cuda()\n",
        "\n",
        "# cost function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ft = optim.SGD(model_VGG16.classifier.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# эвристика\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "id": "7d2a1635",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3735af8"
      },
      "source": [
        "# или разморозка\n",
        "layers_to_unfreeze = 7\n",
        "\n",
        "# Выключаем подсчет градиентов для слоев, которые не будем обучать\n",
        "for param in model_VGG16.features[:-layers_to_unfreeze].parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "num_features = 4096\n",
        "\n",
        "model_VGG16.classifier[6] = nn.Linear(num_features, 42)\n",
        "\n",
        "model_VGG16 = model_VGG16.cuda()\n",
        "\n",
        "# cost function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Обучаем последние layers_to_unfreeze слоев из сверточной части и классифаер\n",
        "optimizer_ft = optim.SGD(list(model_VGG16.features.parameters())[-layers_to_unfreeze:] + \n",
        "                      list(model_VGG16.classifier.parameters()), lr=0.001, momentum=0.9)\n"
      ],
      "id": "f3735af8",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d02cc9c",
        "outputId": "7d2491e6-b5ba-4fa8-db15-8a78741c68c8"
      },
      "source": [
        "model_VGG16"
      ],
      "id": "5d02cc9c",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=42, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d57191a"
      },
      "source": [
        "def trainA(train_files, val_files, model, epochs, batch_size, optimizer, criterion):\n",
        "\n",
        "    import copy\n",
        "    \n",
        "    best_model_wts = model.state_dict()\n",
        "    best_acc = 0.0\n",
        "    \n",
        "    train_loader = DataLoader(train_files, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_files, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    history = []\n",
        "    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
        "    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n",
        "\n",
        "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
        "        opt = optimizer\n",
        "        criterion = criterion\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)\n",
        "            print(\"loss\", train_loss)\n",
        "            \n",
        "            val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n",
        "            history.append((train_loss, train_acc, val_loss, val_acc))\n",
        "            \n",
        "            pbar_outer.update(1)\n",
        "            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n",
        "                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n",
        "            \n",
        "            # если достиглось лучшее качество, то запомним веса модели\n",
        "            if val_acc > best_acc:\n",
        "                best_acc = val_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                \n",
        "        # загрузим лучшие веса модели\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "            \n",
        "    return history, model"
      ],
      "id": "9d57191a",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cb1d88b"
      },
      "source": [
        "def fit_epoch(model, train_loader, criterion, optimizer):\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    processed_data = 0\n",
        "  \n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        preds = torch.argmax(outputs, 1)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        processed_data += inputs.size(0)\n",
        "              \n",
        "    train_loss = running_loss / processed_data\n",
        "    train_acc = running_corrects.cpu().numpy() / processed_data\n",
        "    return train_loss, train_acc"
      ],
      "id": "4cb1d88b",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0372be6"
      },
      "source": [
        "def eval_epoch(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    processed_size = 0\n",
        "\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        with torch.set_grad_enabled(False):\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            preds = torch.argmax(outputs, 1)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        processed_size += inputs.size(0)\n",
        "    val_loss = running_loss / processed_size\n",
        "    val_acc = running_corrects.double() / processed_size\n",
        "    return val_loss, val_acc"
      ],
      "id": "a0372be6",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15c8ac94"
      },
      "source": [
        "обучаем"
      ],
      "id": "15c8ac94"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cfb365f"
      },
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "id": "7cfb365f",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        },
        "id": "b8fb8693",
        "outputId": "93e5ea42-0a3f-486b-8e7a-32d4cf085d5d"
      },
      "source": [
        "%%time\n",
        "epochs = 20\n",
        "batch_size=64\n",
        "\n",
        "historyVGG, model_VGG16 = trainA(train_dataset2, val_dataset2, model_VGG16, epochs, batch_size, optimizer_ft, loss_fn )\n",
        "\n",
        "torch.save(model_VGG16.state_dict(), 'model_VGG16.pth')"
      ],
      "id": "b8fb8693",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\repoch:   0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss 1.9449776469677813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:   5%|▌         | 1/20 [03:52<1:13:31, 232.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 001 train_loss: 1.9450     val_loss 0.9349 train_acc 0.4810 val_acc 0.7482\n",
            "loss 0.6727263565518778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  10%|█         | 2/20 [07:40<1:09:18, 231.00s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 002 train_loss: 0.6727     val_loss 0.5861 train_acc 0.8179 val_acc 0.8473\n",
            "loss 0.42611260434891574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  15%|█▌        | 3/20 [11:30<1:05:23, 230.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 003 train_loss: 0.4261     val_loss 0.4752 train_acc 0.8846 val_acc 0.8745\n",
            "loss 0.3050691748479421\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  20%|██        | 4/20 [15:20<1:01:27, 230.47s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 004 train_loss: 0.3051     val_loss 0.4155 train_acc 0.9151 val_acc 0.8873\n",
            "loss 0.22847897948425389\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  25%|██▌       | 5/20 [19:10<57:33, 230.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 005 train_loss: 0.2285     val_loss 0.3922 train_acc 0.9372 val_acc 0.8951\n",
            "loss 0.17774582059814395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  30%|███       | 6/20 [23:00<53:45, 230.41s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 006 train_loss: 0.1777     val_loss 0.3652 train_acc 0.9512 val_acc 0.9024\n",
            "loss 0.13412669941823765\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  35%|███▌      | 7/20 [26:52<49:59, 230.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 007 train_loss: 0.1341     val_loss 0.3549 train_acc 0.9622 val_acc 0.9085\n",
            "loss 0.10607164231969549\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  40%|████      | 8/20 [30:41<46:02, 230.22s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 008 train_loss: 0.1061     val_loss 0.3744 train_acc 0.9692 val_acc 0.9037\n",
            "loss 0.08834790167316231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  45%|████▌     | 9/20 [34:34<42:20, 230.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 009 train_loss: 0.0883     val_loss 0.3406 train_acc 0.9750 val_acc 0.9131\n",
            "loss 0.07158841919117148\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  50%|█████     | 10/20 [38:27<38:37, 231.72s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 010 train_loss: 0.0716     val_loss 0.4284 train_acc 0.9796 val_acc 0.8987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\repoch:  50%|█████     | 10/20 [38:35<38:35, 231.57s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-704b4a40b4d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"epochs = 20\\nbatch_size=64\\n\\nhistoryVGG, model_VGG16 = trainA(train_dataset2, val_dataset2, model_VGG16, epochs, batch_size, optimizer_ft, loss_fn )\\n\\ntorch.save(model_VGG16.state_dict(), 'model_VGG16.pth')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-998cde3491a8>\u001b[0m in \u001b[0;36mtrainA\u001b[0;34m(train_files, val_files, model, epochs, batch_size, optimizer, criterion)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-9435822a081b>\u001b[0m in \u001b[0;36mfit_epoch\u001b[0;34m(model, train_loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprocessed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-540afcfcc494>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     47\u001b[0m         ])\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-540afcfcc494>\u001b[0m in \u001b[0;36mload_sample\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBDiKpzhrbDW"
      },
      "source": [
        "torch.save(model_VGG16.state_dict(), 'model_VGG16_10epoch.pth')"
      ],
      "id": "QBDiKpzhrbDW",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "4527f256",
        "outputId": "58ea404c-9498-40a5-e3ae-8d63bb89a960"
      },
      "source": [
        "loss, acc, val_loss, val_acc = zip(*historyVGG)"
      ],
      "id": "4527f256",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-085edb827c90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhistoryVGG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'historyVGG' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6567032",
        "outputId": "8c7b4265-f106-47e2-d2f4-6a1da322b451"
      },
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(loss, label=\"train_loss\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()"
      ],
      "id": "d6567032",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c85H3bNirEmA"
      },
      "source": [
        "Качество по классам"
      ],
      "id": "c85H3bNirEmA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHowaFhUsUD9"
      },
      "source": [
        "def predict(model, test_loader):\n",
        "    with torch.no_grad():\n",
        "        logits = []\n",
        "    \n",
        "        for inputs in test_loader:\n",
        "            inputs = inputs.to(DEVICE)\n",
        "            model.eval()\n",
        "            outputs = model(inputs).cpu()\n",
        "            logits.append(outputs)\n",
        "            \n",
        "    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n",
        "    return probs"
      ],
      "id": "NHowaFhUsUD9",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c5dfc81"
      },
      "source": [
        "imgs = [val_dataset2[id][0].unsqueeze(0) for id in range(len(val_dataset2))]\n",
        "\n",
        "actual_labels = [val_dataset2[id][1] for id in range(len(val_dataset2))]\n",
        "\n",
        "probs_ims = predict(model_VGG16, imgs)\n",
        "y_pred = np.argmax(probs_ims,-1)"
      ],
      "id": "7c5dfc81",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNtKmD1zrWft",
        "outputId": "d998b024-06c3-4c3c-aac5-f9c68f097097"
      },
      "source": [
        "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n",
        "\n",
        "print(classification_report(actual_labels, y_pred, target_names=label_encoder.classes_))"
      ],
      "id": "VNtKmD1zrWft",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          precision    recall  f1-score   support\n",
            "\n",
            "  abraham_grampa_simpson       0.97      0.89      0.93       228\n",
            "           agnes_skinner       1.00      0.30      0.46        10\n",
            "  apu_nahasapeemapetilon       0.92      0.93      0.93       156\n",
            "           barney_gumble       0.89      0.62      0.73        26\n",
            "            bart_simpson       0.95      0.95      0.95       336\n",
            "            carl_carlson       0.91      0.88      0.89        24\n",
            "charles_montgomery_burns       1.00      0.77      0.87       298\n",
            "            chief_wiggum       0.90      0.96      0.93       247\n",
            "         cletus_spuckler       0.90      0.75      0.82        12\n",
            "          comic_book_guy       0.88      0.90      0.89       117\n",
            "               disco_stu       0.00      0.00      0.00         2\n",
            "          edna_krabappel       0.98      0.94      0.96       114\n",
            "                fat_tony       1.00      0.86      0.92         7\n",
            "                     gil       0.50      0.43      0.46         7\n",
            "    groundskeeper_willie       0.86      0.83      0.85        30\n",
            "           homer_simpson       0.88      0.96      0.92       562\n",
            "           kent_brockman       0.96      0.97      0.96       125\n",
            "        krusty_the_clown       0.95      0.94      0.95       302\n",
            "           lenny_leonard       0.72      0.88      0.80        77\n",
            "             lionel_hutz       1.00      1.00      1.00         1\n",
            "            lisa_simpson       0.89      0.94      0.92       339\n",
            "          maggie_simpson       0.73      0.50      0.59        32\n",
            "           marge_simpson       0.96      0.94      0.95       323\n",
            "           martin_prince       0.67      0.78      0.72        18\n",
            "            mayor_quimby       0.80      0.84      0.82        61\n",
            "     milhouse_van_houten       0.95      0.96      0.96       270\n",
            "             miss_hoover       1.00      0.75      0.86         4\n",
            "             moe_szyslak       0.94      0.90      0.92       363\n",
            "            ned_flanders       0.88      0.95      0.91       364\n",
            "            nelson_muntz       0.91      0.82      0.86        89\n",
            "               otto_mann       1.00      0.88      0.93         8\n",
            "           patty_bouvier       0.85      0.61      0.71        18\n",
            "       principal_skinner       0.90      0.93      0.91       299\n",
            "    professor_john_frink       0.74      0.88      0.80        16\n",
            "      rainier_wolfcastle       0.67      0.55      0.60        11\n",
            "            ralph_wiggum       1.00      0.95      0.98        22\n",
            "           selma_bouvier       0.66      0.81      0.72        26\n",
            "            sideshow_bob       0.96      0.99      0.97       219\n",
            "            sideshow_mel       0.75      0.60      0.67        10\n",
            "          snake_jailbird       0.56      0.64      0.60        14\n",
            "            troy_mcclure       1.00      0.50      0.67         2\n",
            "         waylon_smithers       0.85      0.89      0.87        45\n",
            "\n",
            "                accuracy                           0.91      5234\n",
            "               macro avg       0.85      0.79      0.81      5234\n",
            "            weighted avg       0.92      0.91      0.91      5234\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GUGV96trptt"
      },
      "source": [
        "test_dataset = SimpsonsDataset2(test_files, mode=\"test\")\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\n",
        "probs = predict(model_VGG16, test_loader)\n",
        "\n",
        "\n",
        "preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))\n",
        "test_filenames = [path.name for path in test_dataset.files]"
      ],
      "id": "4GUGV96trptt",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "lvfx4okQsFs5",
        "outputId": "a4873749-371d-4f35-9ba8-27a22cdb7986"
      },
      "source": [
        "import pandas as pd\n",
        "my_submit = pd.DataFrame({'Id': test_filenames, 'Expected': preds})\n",
        "my_submit.head()"
      ],
      "id": "lvfx4okQsFs5",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Expected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>img0.jpg</td>\n",
              "      <td>nelson_muntz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>img1.jpg</td>\n",
              "      <td>bart_simpson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>img10.jpg</td>\n",
              "      <td>ned_flanders</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>img100.jpg</td>\n",
              "      <td>chief_wiggum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>img101.jpg</td>\n",
              "      <td>apu_nahasapeemapetilon</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Id                Expected\n",
              "0    img0.jpg            nelson_muntz\n",
              "1    img1.jpg            bart_simpson\n",
              "2   img10.jpg            ned_flanders\n",
              "3  img100.jpg            chief_wiggum\n",
              "4  img101.jpg  apu_nahasapeemapetilon"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEgTL6P7svWr"
      },
      "source": [
        "my_submit.to_csv('/content/drive/MyDrive/DLS advanced course/Simpson_competition/model_VGG16_10epoch.csv', index = False)"
      ],
      "id": "DEgTL6P7svWr",
      "execution_count": 40,
      "outputs": []
    }
  ]
}